{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'my_env (Python 3.11.5)' due to a connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "#add website data\n",
    "URL = [\"https://www.geeksforgeeks.org/stock-price-prediction-project-using-tensorflow/\",\n",
    "\t\"https://www.geeksforgeeks.org/training-of-recurrent-neural-networks-rnn-in-tensorflow/\"]\n",
    "\n",
    "#load the data\n",
    "data = WebBaseLoader(URL)\n",
    "#extract the content\n",
    "content = data.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=256,chunk_overlap=50)\n",
    "chunking = text_splitter.split_documents(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# get your free access token from HuggingFace and paste it here\n",
    "HF_token = getpass()\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_token\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "\tapi_key = HF_token,model_name = \"BAAI/bge-base-en-v1.5\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(chunking,embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"mmr\",search_kwargs={\"k\":3})\n",
    "query = \"what is recurrent neural network?\"\n",
    "docs_rel = retriever.get_relevant_documents(query)\n",
    "print(docs_rel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "<|system|>>\n",
    "You are an AI Assistant that follows instructions extremely well.\n",
    "Please be truthful and give direct answers. Please tell 'I don't know' if user query is not in context\n",
    "</s>\n",
    "<|user|>\n",
    "{query}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "model = HuggingFaceHub(repo_id=\"HuggingFaceH4/zephyr-7b-alpha\",\n",
    "\t\t\t\t\tmodel_kwargs={\"temperature\":0.5,\n",
    "\t\t\t\t\t\t\t\t\t\"max_new_tokens\":512,\n",
    "\t\t\t\t\t\t\t\t\t\"max_length\":64\n",
    "\t\t\t\t\t\t\t\t\t})\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(llm=model,retriever=retriever,chain_type=\"stuff\")\n",
    "response = qa(prompt)\n",
    "print(response['result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
